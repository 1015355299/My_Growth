# robots.txt generated at http://tool.chinaz.com/robots/ 
User-agent: Baiduspider
Disallow: 
User-agent: Sosospider
Disallow: 
User-agent: sogou spider
Disallow: 
User-agent: YodaoBot
Disallow: 
User-agent: Googlebot
Disallow: 
User-agent: Bingbot
Disallow: 
User-agent: Slurp
Disallow: 
User-agent: Teoma
Disallow: 
User-agent: ia_archiver
Disallow: 
User-agent: twiceler
Disallow: 
User-agent: MSNBot
Disallow: 
User-agent: Scrubby
Disallow: 
User-agent: Robozilla
Disallow: 
User-agent: Gigabot
Disallow: 
User-agent: googlebot-image
Disallow: 
User-agent: googlebot-mobile
Disallow: 
User-agent: yahoo-mmcrawler
Disallow: 
User-agent: yahoo-blogs/v3.9
Disallow: 
User-agent: psbot
Disallow: 
User-agent: *
Disallow: 
Crawl-delay: 5
Disallow: /
Disallow: /guide/
Disallow: /messages/
Disallow: /reading/
Disallow: /guide/sidebar1/
Disallow: /guide/sidebar2/
Disallow: /guide/sidebar3/
Disallow: /guide/sidebar4/
Disallow: /guide/sidebar5/
Disallow: /guide/sidebar6/
Disallow: /guide/sidebar7/
Disallow: /guide/sidebar8/
Disallow: /guide/sidebar9/
Disallow: /js/
Disallow: /css/
Disallow: /html/
Disallow: /data-structure/
Disallow: /algorithm/
Disallow: /browser/
Disallow: /operating-system/
Disallow: /network/
Disallow: /security/
Disallow: /vue/
Disallow: /design-pattern/
Disallow: /gulp/
Disallow: /webpack/
Disallow: /nodejs/
Disallow: /others/
Sitemap: https://docs.5102it.cn/docs.5102it.cn.xml
Sitemap: https://docs.5102it.cn/docs.5102it.cn.html